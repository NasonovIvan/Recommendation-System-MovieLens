{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re, os, pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df = pd.read_csv('../datasets/movies.csv')\n",
    "# I used only 2 million items from ratings due to the lack of computer power\n",
    "ratings_df = pd.read_csv('../datasets/ratings.csv').iloc[:2000000, :]  # Change the \"2000000\" to your desired size\n",
    "tags_df = pd.read_csv('../datasets/tags.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving the data out of ratings_df and tags_df for the last movie the user liked to be used as the label:\n",
    "# Rating of 4+ = liked\n",
    "# Creating directories:\n",
    "if os.path.exists('data/') != True:\n",
    "    os.mkdir('data/')\n",
    "    \n",
    "# if os.path.exists('data/last_liked_tags/') != True: \n",
    "#     os.mkdir('data/last_liked_tags/')\n",
    "    \n",
    "# Getting the last movie liked from ratings_df:\n",
    "ratings_df_copy = ratings_df.copy()\n",
    "tags_df_copy = tags_df.copy()\n",
    "\n",
    "users_list = list(set(ratings_df_copy.userId)) # List of all users in the dataset\n",
    "\n",
    "ratings_index_list = [] # These empty lists will be used to remove the last liked movies from the ratings_df and tags_df_mod copies\n",
    "tags_index_list = []\n",
    "\n",
    "last_ratings_df = pd.DataFrame() # Want to save all the last liked movies rated into a single CSV file\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for user in users_list:\n",
    "    try: # Some users did not rate a movie highly enough and will be removed from the dataset\n",
    "        temp_df = ratings_df_copy[ratings_df_copy.userId == user].copy()\n",
    "        temp_df = temp_df[temp_df.rating >= 4] # = Liked Movie\n",
    "\n",
    "        last_time = max(temp_df.timestamp) # If the user did not have a \"liked\" movie, this will return an error\n",
    "\n",
    "        temp_df = temp_df[temp_df.timestamp == last_time] # Isolating the last liked movie rated for each user\n",
    "        \n",
    "        if len(temp_df) > 1: # Some of the movies were rated at the same timestamp; only the last one on spliced DF will be removed\n",
    "            temp_df = temp_df.iloc[[len(temp_df)-1]]\n",
    "            \n",
    "        ratings_index_list.append(temp_df.index.values[0]) # Appending the index of the last movies watched\n",
    "\n",
    "        if counter == 0:\n",
    "            last_ratings_df = temp_df\n",
    "            counter = 1\n",
    "\n",
    "        else:\n",
    "            last_ratings_df = pd.concat([last_ratings_df, temp_df], ignore_index= True)\n",
    "        \n",
    "    except Exception:\n",
    "        ratings_index_list.append(ratings_df_copy[ratings_df_copy.userId == user].index.values[0]) # Adding the index of the users whom did not highly rate a movie\n",
    "    \n",
    "    try:  # Some users have not created tags\n",
    "        temp_df = tags_df_copy[tags_df_copy.userId == user].copy()\n",
    "        temp_df = temp_df[temp_df.rating >= 4]\n",
    "        last_movie = temp_df.movieId.values[0]\n",
    "        temp_df = temp_df[temp_df.movieId == last_movie]\n",
    "        \n",
    "        \n",
    "        if len(temp_df) == 0: # most users did not create tag(s) for the last movie liked!\n",
    "            continue\n",
    "            \n",
    "        else:\n",
    "            temp_df.to_csv('data/last_liked_tags/' + str(user) + '.csv', index = False)  #!! these tags will not be used and is stored for examination purposes;\n",
    "            # these must be removed for \"proper\" datasets when training to exclude data related to the label from being used in the training data\n",
    "            tags_index_list.extend(list(temp_df.index.values))  # This is a .extend since there are most likely more than one timestamp per movie\n",
    "    \n",
    "    except Exception:\n",
    "        pass\n",
    "    \n",
    "last_ratings_df.to_csv('data/last_liked_ratings.csv', index = False)\n",
    "\n",
    "# Removing the last movies from ratings_df_copy and tags_df_copy:\n",
    "ratings_df_removed = ratings_df_copy.drop(ratings_index_list)\n",
    "\n",
    "tags_df_removed = tags_df_copy.drop(tags_index_list)\n",
    "\n",
    "ratings_df_removed.to_csv('data/ratings_df_last_liked_movie_removed.csv', index = False)\n",
    "tags_df_removed.to_csv('data/tags_df_last_liked_movie_removed.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting 'timestamp' column since it is not informative (not examining viewer's social behaviors)\n",
    "# Droping all NaN values, which is only seen in the tag column--this is to eliminate considering NaNs when looping below\n",
    "tags_df_removed = pd.read_csv('data/tags_df_last_liked_movie_removed.csv')\n",
    "\n",
    "tags_df_mod = tags_df_removed.copy().drop('timestamp', axis=1).dropna()\n",
    "tags_df_mod['tag'] = tags_df_mod['tag'].str.lower()# Making all tags lowercased for uniform format\n",
    "\n",
    "\n",
    "for index, row in tags_df_mod.iterrows():\n",
    "    tag = row.tag#.split()  # splitting words for spell check (if need)\n",
    "    \n",
    "    correct_tag = re.sub(r' \\([^)]*\\)', '', tag)  # Removing all parenthesis and its contents, including the whitespace before\n",
    "        \n",
    "    # First if:\n",
    "    if 'based' in correct_tag: # This is necessary because it is a common tag and avoids the other if statements downstream\n",
    "        tags_df_mod.loc[index, 'tag'] = correct_tag\n",
    "        continue\n",
    "        \n",
    "    # Second if:    \n",
    "    if '-' in correct_tag: # This is to keep \"sci-fi\" from being removed in the next if statement\n",
    "        tags_df_mod.loc[index, 'tag'] = correct_tag\n",
    "        continue\n",
    "        \n",
    "    # Third if:    \n",
    "    if re.findall(r'\\b\\w{2}\\b', correct_tag):\n",
    "        tags_df_mod.loc[index, 'tag'] = np.NaN # Replacing two-letter words; Need to maintain index ordering, will delete NaNs later\n",
    "        \n",
    "    elif re.findall(r'\\b\\w{1}\\b', correct_tag):\n",
    "        tags_df_mod.loc[index, 'tag'] = np.NaN # Replacing one-letter words\n",
    "        \n",
    "    elif tag == correct_tag: # This is for better performance since replacing significantly slows the process\n",
    "        continue\n",
    "        \n",
    "    else:\n",
    "        tags_df_mod.loc[index, 'tag'] = correct_tag # Saves the corrected tag\n",
    "        pass\n",
    "        \n",
    "tags_df_mod = tags_df_mod.dropna() # Dropping all tags with words that are lower than two letters or less\n",
    "\n",
    "tags_df_mod.to_csv('data/tags_df_mod.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new DF that contains the most common tags for each movie (\"movieId\"):\n",
    "\n",
    "# This will create a new DF for each movie and will store this file since there is no easy storage method for this task\n",
    "# Storage will be in the \"data\" folder under the \"movie_tags\" subfolder:\n",
    "    \n",
    "if os.path.exists('data/movie_tags/') != True: # Creating movie_tags subfolder\n",
    "    os.mkdir('data/movie_tags/')\n",
    "    \n",
    "# Creating a copy of tags_df_mod and dropping userID:\n",
    "tags_df_mod = pd.read_csv('data/tags_df_mod.csv')\n",
    "\n",
    "tags_df_no_user = tags_df_mod.copy().drop('userId', axis= 1)\n",
    "\n",
    "# Obtaining a list of all movieId with tags:\n",
    "# !! The set() function does not put the list in perfect order. Some of the IDs are out-of-place.\n",
    "movieId_list = list(set(tags_df_no_user.movieId))  \n",
    "\n",
    "for movieId in movieId_list:\n",
    "    df_select = tags_df_no_user[tags_df_no_user.movieId == movieId].copy().drop('movieId', axis= 1)\n",
    "    \n",
    "    df_select['COUNT'] = 1\n",
    "    \n",
    "    df_select_group = df_select.groupby(['tag']).count()\n",
    "    \n",
    "    df_select_group = df_select_group.sort_values(by=['COUNT'], ascending= False).reset_index()\n",
    "    \n",
    "    df_select_group.to_csv('data/movie_tags/' + str(movieId) + '.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new DF that contains the most common tags for each user (\"userId\"):\n",
    "# This DF is similar to the movieId DF that is previously created except this ties the tags in with each user\n",
    "# This can be used in conjunction with the most common genres watched by the user to help determine which movies they like to watch\n",
    "if os.path.exists('data/user_tags/') != True: # Creating movie_tags subfolder\n",
    "    os.mkdir('data/user_tags/')\n",
    "    \n",
    "# Creating a copy of tags_df_mod and dropping userID:\n",
    "tags_df_mod = pd.read_csv('data/tags_df_mod.csv')\n",
    "\n",
    "tags_df_user = tags_df_mod.copy().drop('movieId', axis= 1)\n",
    "\n",
    "# Obtaining a list of all movieId with tags:\n",
    "userId_list = list(set(tags_df_user.userId))\n",
    "\n",
    "for userId in userId_list:\n",
    "    df_select = tags_df_user[tags_df_user.userId == userId].copy().drop('userId', axis= 1)\n",
    "    \n",
    "    df_select['COUNT'] = 1\n",
    "    \n",
    "    df_select_group = df_select.groupby(['tag']).count()\n",
    "    \n",
    "    df_select_group = df_select_group.sort_values(by=['COUNT'], ascending= False).reset_index()\n",
    "    \n",
    "    df_select_group.to_csv('data/user_tags/' + str(userId) + '.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating another DF that contains the most common tags created by users:\n",
    "# Common = the tag was used 35 times or more\n",
    "tags_df_mod = pd.read_csv('data/tags_df_mod.csv')\n",
    "\n",
    "common_tags_df = tags_df_mod.groupby(['tag']).count().sort_values('userId', ascending= False).copy().drop('movieId', axis= 1).reset_index()\n",
    "\n",
    "common_tags_df = common_tags_df[common_tags_df.userId >= 35]\n",
    "\n",
    "common_tags_df.to_csv('data/common_tags.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df_removed = pd.read_csv('data/ratings_df_last_liked_movie_removed.csv')\n",
    "movies_df_mod = movies_df.copy()\n",
    "\n",
    "movies_df_mod['YEAR'] = 0\n",
    "movies_df_mod['UPPER_STD'] = 0\n",
    "movies_df_mod['LOWER_STD'] = 0\n",
    "movies_df_mod['AVG_RATING'] = 0\n",
    "movies_df_mod['VIEW_COUNT'] = 0\n",
    "\n",
    "# Making the genres into columns:\n",
    "# First, need to obtain a list of all the genres in the dataset.\n",
    "# !! Note: \"IMAX\" is not listed in the readme but is present in the dataset.\n",
    "genres_list = []\n",
    "for index, row in movies_df.iterrows():\n",
    "    try:\n",
    "        genres = row.genres.split('|')\n",
    "        genres_list.extend(genres)\n",
    "    except:\n",
    "        genres_list.append(row.genres)\n",
    "        \n",
    "genres_list = list(set(genres_list))\n",
    "genres_list.remove('IMAX')\n",
    "genres_list.remove('(no genres listed)') # Replace with 'None'\n",
    "genres_list.append('None')\n",
    "\n",
    "for genre in genres_list: # Creating new columns with names as genres\n",
    "    movies_df_mod[genre] = 0  # 0 = movie is not considered in that genre\n",
    "\n",
    "\n",
    "for index, row in movies_df_mod.iterrows():\n",
    "    movieId = row.movieId\n",
    "    title = row.title\n",
    "    \n",
    "    try:\n",
    "        genres = row.genres.split('|') # Multiple genres for the movie is separated by '|' in the one string; converts to list\n",
    "    except Exception:\n",
    "        genres = list(row.genres) # In the case that there is only one genre for the movie\n",
    "        \n",
    "    \n",
    "    # Extracting the year from the title:\n",
    "    try: # Some titles do not have the year--these will be removed downstream to remove the need to access the IMDB API (http://www.omdbapi.com/)\n",
    "        matcher = re.compile('\\(\\d{4}\\)')  # Need to extract '(year)' from the title in case there is a year in the title\n",
    "        parenthesis_year = matcher.search(title).group(0)\n",
    "        matcher = re.compile('\\d{4}') # Matching the year from the already matched '(year)'\n",
    "        year = matcher.search(parenthesis_year).group(0)\n",
    "\n",
    "        movies_df_mod.loc[index, 'YEAR'] = int(year)\n",
    "    \n",
    "    except Exception:\n",
    "        pass\n",
    "    \n",
    "    # Merging info from ratings_df into movies_df\n",
    "    try:\n",
    "        ratings_df_select = ratings_df_removed[ratings_df_removed.movieId == movieId]  # Gathering the reviews for the movies\n",
    "        std = np.std(ratings_df_select.rating)\n",
    "        average_rating = np.mean(ratings_df_select.rating)\n",
    "\n",
    "        upper_std = average_rating + std\n",
    "\n",
    "        if upper_std > 5:   # This is to prevent the upper range from passing the max rating value\n",
    "            upper_std = 5\n",
    "\n",
    "        lower_std = average_rating - std\n",
    "\n",
    "        if lower_std < 0.5:\n",
    "            lower_std = 0.5\n",
    "\n",
    "        view_count = len(ratings_df_select)\n",
    "\n",
    "        movies_df_mod.loc[index, 'UPPER_STD'] = upper_std\n",
    "        movies_df_mod.loc[index, 'LOWER_STD'] = lower_std\n",
    "        movies_df_mod.loc[index, 'AVG_RATING'] = average_rating\n",
    "        movies_df_mod.loc[index, 'VIEW_COUNT'] = view_count\n",
    "        \n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    \n",
    "    # Changing all columns that are labelled as genres to 1 if the movie is in that genre:\n",
    "    if 'IMAX' in genres:\n",
    "        genres.remove('IMAX')\n",
    "        \n",
    "    if '(no genres listed)' in genres:\n",
    "        genres.remove('(no genres listed)')\n",
    "        genres.append('None')\n",
    "        \n",
    "    for genre in genres:\n",
    "        movies_df_mod.loc[index, genre] = 1\n",
    "        \n",
    "movies_df_mod = movies_df_mod[movies_df_mod.YEAR != 0] # Removing all movies without years in the title\n",
    "movies_df_mod = movies_df_mod[movies_df_mod.VIEW_COUNT != 0] # Removing all movies than have not be rated\n",
    "\n",
    "movies_df_mod.to_csv('data/movies_mod.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.001492760113448 %\n",
      "20.002985520226897 %\n",
      "30.00447828034035 %\n",
      "40.00099517340897 %\n",
      "50.002487933522424 %\n",
      "60.00398069363586 %\n",
      "70.00049758670448 %\n",
      "80.00199034681793 %\n",
      "90.00348310693138 %\n",
      "100.0 %\n"
     ]
    }
   ],
   "source": [
    "# Combining ratings_df and movies_df_mod together:\n",
    "movies_df_mod = pd.read_csv('data/movies_mod.csv')\n",
    "\n",
    "ratings_df_removed = pd.read_csv('data/ratings_df_last_liked_movie_removed.csv')\n",
    "\n",
    "ratings_movies_df = ratings_df_removed.merge(movies_df_mod, how= 'left', on= 'movieId').dropna()  # Some of the movies were removed when creating movies_df_mod, which will result in nan values for some rows\n",
    "\n",
    "# Getting a count of all the liked and dislike genres and transforming it into a percentage (liked genre counts / all liked genres counts)\n",
    "# If the user rated the movie 4+, then they liked it. If lower than 4, then they disliked it.\n",
    "users_list = list(set(ratings_movies_df.userId))\n",
    "\n",
    "total_user_like_df = pd.DataFrame()\n",
    "total_user_dislike_df = pd.DataFrame()\n",
    "\n",
    "progress_counter_1 = 0\n",
    "progress_counter_2 = .10\n",
    "\n",
    "for user in users_list:\n",
    "    temp_df = ratings_movies_df[ratings_movies_df.userId == user]\n",
    "    like_df = temp_df[temp_df.rating >= 4].iloc[:, 14:] # Only selecting the genres\n",
    "    dislike_df = temp_df[temp_df.rating < 4].iloc[:, 14:]\n",
    "    \n",
    "    liked_total_counts = 0\n",
    "    liked_dict = {'userId': user,'War': 0, 'Animation': 0, 'Horror': 0, 'Sci-Fi': 0, 'Fantasy': 0, 'Thriller': 0, 'Crime': 0, 'Mystery': 0, \n",
    "                  'Documentary': 0, 'Children': 0, 'Action': 0, 'Adventure': 0, 'Musical': 0,'Film-Noir': 0, 'Drama': 0, \n",
    "                  'Romance': 0, 'Comedy': 0, 'Western': 0, 'None': 0}\n",
    "    \n",
    "    disliked_total_counts = 0\n",
    "    disliked_dict = {'userId': user,'War': 0, 'Animation': 0, 'Horror': 0, 'Sci-Fi': 0, 'Fantasy': 0, 'Thriller': 0, 'Crime': 0, 'Mystery': 0, \n",
    "                  'Documentary': 0, 'Children': 0, 'Action': 0, 'Adventure': 0, 'Musical': 0,'Film-Noir': 0, 'Drama': 0, \n",
    "                  'Romance': 0, 'Comedy': 0, 'Western': 0, 'None': 0}   \n",
    "    \n",
    "    progress_counter_1 += 1\n",
    "    if progress_counter_1 / len(users_list) >= progress_counter_2:\n",
    "        print(progress_counter_1 / len(users_list) * 100, '%')\n",
    "        progress_counter_2 += .10\n",
    "    \n",
    "    for genre in list(like_df.columns): # Getting all the genre counts for liked and disliked, separately\n",
    "        if len(like_df) == 0: # If the user has not given a movie a rating of 4 or higher\n",
    "            pass\n",
    "        \n",
    "        else:\n",
    "            liked_total_counts += sum(like_df[genre])\n",
    "        \n",
    "        \n",
    "        if len(dislike_df) == 0: # If the user has not given a movie a rating of 3.5 or lower\n",
    "            pass\n",
    "        \n",
    "        else:\n",
    "            disliked_total_counts += sum(dislike_df[genre])\n",
    "        \n",
    "        \n",
    "    for genre in list(like_df.columns):\n",
    "        if liked_total_counts == 0: \n",
    "            pass\n",
    "        \n",
    "        else:\n",
    "            liked_genre_total_counts = sum(like_df[genre])\n",
    "            liked_dict[genre] = liked_genre_total_counts/liked_total_counts\n",
    "            \n",
    "            \n",
    "        if disliked_total_counts == 0:\n",
    "            pass\n",
    "        \n",
    "        else:\n",
    "            disliked_genre_total_counts = sum(dislike_df[genre])\n",
    "            disliked_dict[genre] = disliked_genre_total_counts/disliked_total_counts\n",
    "        \n",
    "    \n",
    "    user_like_df = pd.DataFrame(liked_dict, index=[0]) # Even though some users have not rated a movie higher or lower than 4, the zero counts will still be added for complete-ness\n",
    "    user_dislike_df = pd.DataFrame(disliked_dict, index=[0])\n",
    "    \n",
    "    # Concatenating the user total counts \n",
    "    if len(total_user_like_df) == 0:\n",
    "        total_user_like_df = user_like_df\n",
    "    \n",
    "    else:\n",
    "        total_user_like_df = pd.concat([total_user_like_df, user_like_df], ignore_index= True)\n",
    "        \n",
    "    if len(total_user_dislike_df) == 0:\n",
    "        total_user_dislike_df = user_dislike_df\n",
    "        \n",
    "    else:\n",
    "        total_user_dislike_df = pd.concat([total_user_dislike_df, user_dislike_df], ignore_index= True)\n",
    "        \n",
    "total_user_like_df.to_csv('data/total_user_like_df.csv', index = False)\n",
    "total_user_dislike_df.to_csv('data/total_user_dislike_df.csv', index = False)\n",
    "        \n",
    "#####################\n",
    "# The reason why the counts are in percentage is so that the counts/genres are scaled against each other rather than a raw count\n",
    "# This is more important for the models since someone who rated a lot of movies vs someone who rated a few movies would have higher counts\n",
    "# but the higher counts is not meaningful and will most likely skew the model weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! This cell will most likely take over 2 days or more on a personal system or laptop\n",
    "# ! A premade CSV and pickle files are already included in the GitHub file (like_dislike_tags.csv) if not wanting to wait and the original dataset is the \"MovieLens 25M Dataset\".\n",
    "# ! Else, remove the '#' before running this cell.\n",
    "\n",
    "# Creating a dictionary of vectorized tags:\n",
    "if os.path.exists('data/final/') != True:\n",
    "    os.mkdir('data/final/')\n",
    "\n",
    "\n",
    "# common_tags = pd.read_csv('data/common_tags.csv', index_col= False)\n",
    "\n",
    "# tags = list(set(common_tags.tag))\n",
    "\n",
    "# vector_counter = 0\n",
    "# vectorized_dict = {}\n",
    "\n",
    "# for tag in tags:\n",
    "#     vectorized_dict[tag] = vector_counter\n",
    "#     vector_counter += 1\n",
    "\n",
    "# ratings_df_removed = pd.read_csv('data/ratings_df_last_liked_movie_removed.csv')\n",
    "\n",
    "# user_list = list(set(ratings_df_removed.userId))\n",
    "\n",
    "# like_dislike_tags = pd.DataFrame()\n",
    "# index_counter = 0\n",
    "\n",
    "# progress_counter_1 = 0\n",
    "# progress_counter_2 = 5\n",
    "# start_time = datetime.datetime.now()\n",
    "# print('Start Time:', start_time)\n",
    "\n",
    "# for user in user_list:\n",
    "#     progress_counter_1 += 1\n",
    "\n",
    "#     temp_ratings_df = ratings_df_removed[ratings_df_removed.userId == user]\n",
    "#     like_tags_df = pd.DataFrame()\n",
    "#     dislike_tags_df = pd.DataFrame()\n",
    "        \n",
    "#     for index, row in temp_ratings_df.iterrows():  # Creating tags for each user\n",
    "#         try: # This is to check if the movie tags exist\n",
    "#             if row.rating >= 4: # Like\n",
    "#                 temp_movie_df = pd.read_csv('data/movie_tags/{}.csv'.format(str(int(row.movieId)))) # This oddly turns the movieId into a float, most likely to match the other data types in the selected series\n",
    "\n",
    "#                 if len(like_tags_df) == 0:\n",
    "#                     like_tags_df = temp_movie_df\n",
    "\n",
    "#                 else:\n",
    "#                     like_tags_df = pd.concat([like_tags_df, temp_movie_df], ignore_index= True)\n",
    "\n",
    "#             else:\n",
    "#                 temp_movie_df = pd.read_csv('data/movie_tags/{}.csv'.format(str(int(row.movieId))))\n",
    "\n",
    "#                 if len(like_tags_df) == 0:\n",
    "#                     dislike_tags_df = temp_movie_df\n",
    "\n",
    "#                 else:\n",
    "#                     dislike_tags_df = pd.concat([dislike_tags_df, temp_movie_df], ignore_index= True)\n",
    "#         except Exception:\n",
    "#             pass\n",
    "                \n",
    "#     # Counting all tags\n",
    "#     try:  # This is to check if the user has movies they've liked or disliked. Users who only have liked movies will be skipped (example: userId 173)\n",
    "#         like_tags_list = list(like_tags_df.tag)\n",
    "#         dislike_tags_list = list(dislike_tags_df.tag)\n",
    "#     except Exception:\n",
    "#         continue\n",
    "    \n",
    "#     like_dict = {}\n",
    "#     dislike_dict = {}\n",
    "    \n",
    "#     for tag in like_tags_list:\n",
    "#         like_dict[tag] = like_tags_list.count(tag) * -1  # This is multiple by -1 to convert it to a negative numerical count for the sorting that will be done next\n",
    "    \n",
    "#     for tag in dislike_tags_list:\n",
    "#         dislike_dict[tag] = dislike_tags_list.count(tag) * -1\n",
    "        \n",
    "#     # Sorting the dictionary by the tag counts (smallest to largest is by default and simplest; in this case, the multiplication by -1 makes the tags with the largest counts the first in the sorted list)\n",
    "#     like_tags_counted = sorted(like_dict, key= lambda tag: like_dict[tag])  # Returns a list of the tags\n",
    "#     dislike_tags_counted = sorted(dislike_dict, key= lambda tag: dislike_dict[tag])\n",
    "    \n",
    "#     # Converting the tags to vectorized tags but only for the first 50 tags from the like and dislike tags counted lists\n",
    "#     like_tags_vectorized = []\n",
    "#     dislike_tags_vectorized = []\n",
    "    \n",
    "#     if len(like_tags_counted) < 50:  # Checking to make sure there is 50 tags in the counted lists\n",
    "#         num_like_tags = len(like_tags_counted)\n",
    "#     else:\n",
    "#         num_like_tags = 50\n",
    "        \n",
    "#     if len(dislike_tags_counted) < 50: \n",
    "#         num_dislike_tags = len(like_tags_counted)\n",
    "#     else:\n",
    "#         num_dislike_tags = 50\n",
    "    \n",
    "#     for tag in like_tags_counted[:num_like_tags]:\n",
    "#         try:  # The tag might not exist in the vectorized dictionary\n",
    "#             tag_vector = vectorized_dict[tag]\n",
    "#             like_tags_vectorized.append(tag_vector)\n",
    "#         except Exception:\n",
    "#             pass\n",
    "        \n",
    "#     for tag in dislike_tags_counted[:num_dislike_tags]:\n",
    "#         try:\n",
    "#             tag_vector = vectorized_dict[tag]\n",
    "#             dislike_tags_vectorized.append(tag_vector)\n",
    "#         except Exception:\n",
    "#             pass\n",
    "        \n",
    "#     if len(like_tags_vectorized) < 20 or len(dislike_tags_vectorized) < 20:\n",
    "#         continue  # If any of the two are not 20 tags in length, then the user will be skipped\n",
    "    \n",
    "#     # Obtaining the most liked and disliked tags, 20 tags each, and adding it to like_dislike_tags:\n",
    "#     like_dislike_dict = {}\n",
    "    \n",
    "#     like_dislike_dict['userId'] = user\n",
    "    \n",
    "#     for x in range(20):\n",
    "#         like_dislike_dict['LIKE_' + str(x)] = like_tags_vectorized[x]\n",
    "#         like_dislike_dict['DISLIKE_' + str(x)] = dislike_tags_vectorized[x]\n",
    "    \n",
    "#     concat_df = pd.DataFrame(like_dislike_dict, index=[0])\n",
    "    \n",
    "#     if len(like_dislike_tags) == 0:\n",
    "#         like_dislike_tags = concat_df\n",
    "    \n",
    "#     else:\n",
    "#         like_dislike_tags = pd.concat([like_dislike_tags, concat_df], ignore_index= True)\n",
    "    \n",
    "#     if (progress_counter_1 / len(user_list)) * 100 >= progress_counter_2:\n",
    "#         print((progress_counter_1 / len(user_list)) * 100, '% completed')\n",
    "#         print('Processing Time:', datetime.datetime.now() - start_time)\n",
    "#         print('Current Time:', datetime.datetime.now())\n",
    "#         progress_counter_2 += 5\n",
    "\n",
    "# like_dislike_tags = like_dislike_tags.astype('int64')\n",
    "# like_dislike_tags.to_csv('data/final/like_dislike_tags.csv', index = False)\n",
    "# with open('data/vectorized_dict.pkl', 'wb') as writer:\n",
    "#     # Saving the vectorized tag dictionary as a pickle file; this is the reference to know which vector is associated to the tag!! (string)\n",
    "#     pickle.dump(vectorized_dict, writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.000771724031487 % completed\n",
      "10.001543448062973 % completed\n",
      "15.00231517209446 % completed\n",
      "20.003086896125946 % completed\n",
      "25.01929310078716 % completed\n",
      "30.000771724031488 % completed\n",
      "35.005402068220405 % completed\n",
      "40.00617379225189 % completed\n",
      "45.00308689612594 % completed\n",
      "50.0 % completed\n",
      "55.00077172403148 % completed\n",
      "60.0169779286927 % completed\n",
      "65.00231517209446 % completed\n",
      "70.00308689612595 % completed\n",
      "75.0 % completed\n",
      "80.00077172403148 % completed\n",
      "85.00154344806298 % completed\n",
      "90.00231517209446 % completed\n",
      "95.00694551628338 % completed\n",
      "100.0 % completed\n"
     ]
    }
   ],
   "source": [
    "# Creating a movie tags profile to complement the user tags:\n",
    "if os.path.exists('data/final/') != True:\n",
    "    os.mkdir('data/final/')\n",
    "    \n",
    "movies_df_mod = pd.read_csv('data/movies_mod.csv')\n",
    "movieId_list = list(movies_df_mod.movieId)\n",
    "del movies_df_mod\n",
    "\n",
    "movie_tags_df = pd.DataFrame()\n",
    "index_counter = 0\n",
    "\n",
    "progress_counter_1 = 0\n",
    "progress_counter_2 = 5\n",
    "\n",
    "with open('data/vectorized_dict.pkl', 'rb') as reader:\n",
    "    vectorized_dict = pickle.load(reader)\n",
    "\n",
    "for movie in movieId_list:\n",
    "    progress_counter_1 += 1\n",
    "\n",
    "    try:\n",
    "        temp_df = pd.read_csv('data/movie_tags/{}.csv'.format(movie))  # The tags are already in order of most counts and then alphabetically\n",
    "\n",
    "        if len(temp_df) < 5: # Skipping movies with less than 5 tags\n",
    "            continue \n",
    "\n",
    "        vectorized_tag = []\n",
    "        movie_tags = list(temp_df.tag)\n",
    "\n",
    "        for tag in movie_tags:\n",
    "            try:\n",
    "                tag_vector = vectorized_dict[tag]\n",
    "                vectorized_tag.append(tag_vector)\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "        if len(vectorized_tag) < 5: # Skipping movies with less than 5 common tags; The first similar if statement is not needed but is placed for performance purposes\n",
    "            continue \n",
    "\n",
    "        movie_tags_df.loc[index_counter, 'movieId'] = movie\n",
    "\n",
    "        for x in range(5):\n",
    "            movie_tags_df.loc[index_counter, 'TAG_' + str(x)] = vectorized_tag[x]\n",
    "            \n",
    "        index_counter += 1\n",
    "            \n",
    "    except Exception:\n",
    "        pass\n",
    "    \n",
    "    if (progress_counter_1 / len(movieId_list)) * 100 >= progress_counter_2:\n",
    "        print((progress_counter_1 / len(movieId_list)) * 100, '% completed')\n",
    "        progress_counter_2 += 5\n",
    "\n",
    "movie_tags_df.to_csv('data/final/movie_tags_df.csv', index = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# delete files, which is not usefull for us in the subsequent code\n",
    "shutil.rmtree('data/movie_tags/', ignore_errors=True)\n",
    "shutil.rmtree('data/user_tags/', ignore_errors=True)\n",
    "os.remove('data/common_tags.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5c7b89af1651d0b8571dde13640ecdccf7d5a6204171d6ab33e7c296e100e08a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
